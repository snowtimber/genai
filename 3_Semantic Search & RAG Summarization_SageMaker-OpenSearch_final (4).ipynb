{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d39daf0-b412-4045-ace3-e66ca6f3873a",
   "metadata": {},
   "source": [
    "# Semantic Search & RAG with Amazon OpenSearch Service & SageMaker\n",
    "\n",
    "Notes:\n",
    "run on ml.t3.2xlarge\n",
    "\n",
    "## Trail Guide for Document Search & Summarization\n",
    "\n",
    "### Suggested Trail Marker Times:\n",
    "\n",
    "1. 0:30 min - Deploy LLMs (one for embeddings and one+ for text summarization)\n",
    "\n",
    "2. 0:50 min – Download, Extract, & Ingest arxiv metadata dataset into Pandas Dataframe\n",
    "\n",
    "3. 1:15 – OpenSearch domain created, index defined/created, and connection made\n",
    "\n",
    "4. 1:45 – Vectorize the abstract for 10,000 documents using the GPT-J Embedding model\n",
    "\n",
    "5. 2:00 – Load 10,000 articles into OpenSearch index including abstract_vector, title, categories, update_date, abstract\n",
    "\n",
    "6. 2:15 – Return Relevant Semantic Search Results in a scored table\n",
    "\n",
    "7. 2:30 – Return the high level bullet points of the 3 most relevant articles for a search.\n",
    "\n",
    "(of course feel free to ask one of us if you need a hint)\n",
    "\n",
    "---\n",
    "### What are embeddings and vectors?\n",
    "\n",
    "![word_vector2](word2vec.png)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa6d75-295a-49d4-a05c-e6528655b6d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3919b-4d4d-4af1-919c-ed9eec1ab53f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install OpenSearch ML Python library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afef6989-f0a9-4d71-97a9-198e3f37b2cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q boto3\n",
    "!pip install -q requests\n",
    "# !pip install -q requests-aws4auth\n",
    "!pip install -q opensearch-py\n",
    "!pip install -q tqdm\n",
    "# !pip install -q boto3\n",
    "!pip install -q install transformers[torch]\n",
    "!pip install -q transformers\n",
    "# !pip install -q sentence-transformers rank_bm25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449ab10-2695-4381-96ed-e76bac600c12",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 1. Deploy LLMs (embedding and text summarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2168a0-c65b-42b5-ab2a-7acf78786e0a",
   "metadata": {},
   "source": [
    "## Quick Code scripts to deploy LLM models to SageMaker Inference Endpoints\n",
    "## First, check available Jumpstart Models and use dropdown selector\n",
    "### LLM Models in Jumpstart (all models from huggingface)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0c9e5-abeb-4783-8cca-540b1d24f9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "from ipywidgets import Dropdown\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "from sagemaker.jumpstart.filters import And\n",
    "\n",
    "# Mistral 6b embedding model as default\n",
    "# llm_model_id, llm_model_version = \"huggingface-textgeneration-open-llama\", \"*\"\n",
    "llm_model_id, llm_model_version = \"huggingface-llm-mistral-7b\", \"*\"\n",
    "\n",
    "filter_value = And( \"framework == huggingface\")\n",
    "text_generation_models = list_jumpstart_models(filter=filter_value)\n",
    "\n",
    "llm_dropdown = Dropdown(\n",
    "    value=llm_model_id,\n",
    "    options=text_generation_models,\n",
    "    description=\"Sagemaker Pre-Trained Text Generation Models:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n",
    "display(IPython.display.Markdown(\"## Select a pre-trained Text Generation model from the dropdown below\"))\n",
    "display(llm_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8327ce-425f-4aa5-98bd-e2557f6b695f",
   "metadata": {},
   "source": [
    "### Deploy LLM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5db5d-f31d-4d6a-a0f2-94767c9b85a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "llm_model = JumpStartModel(model_id=llm_dropdown.value, model_version=llm_model_version)#, instance_type='ml.g5.12xlarge')\n",
    "llm_predictor = llm_model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7cfa2-0623-4e43-a838-89aaa53fc46b",
   "metadata": {},
   "source": [
    "### Jumpstart Embedding Model Dropdown Selector (task == textembedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ac018d-d3f4-47f1-83cd-621f5fc6dcdd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "from ipywidgets import Dropdown\n",
    "from sagemaker.jumpstart.notebook_utils import list_jumpstart_models\n",
    "from sagemaker.jumpstart.filters import And\n",
    "\n",
    "# GPT-J-6b embedding model as default\n",
    "embed_model_id, embed_model_version = \"huggingface-textembedding-gpt-j-6b-fp16\", \"*\"\n",
    "\n",
    "filter_value = And(\"task == textembedding\", \"framework == huggingface\")\n",
    "embedding_models = list_jumpstart_models(filter=filter_value)\n",
    "embedding_models\n",
    "\n",
    "embed_dropdown = Dropdown(\n",
    "    value=embed_model_id,\n",
    "    options=embedding_models,\n",
    "    description=\"Sagemaker Pre-Trained Text Embedding Models:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n",
    "display(IPython.display.Markdown(\"## Select a pre-trained embedding model from the dropdown below\"))\n",
    "display(embed_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9a8a44-88c9-4a4d-b32d-ea0d4e990f5b",
   "metadata": {},
   "source": [
    "### Deploy Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7772495-73e7-424d-8dfd-9d1d85d0a3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "embedding_model = JumpStartModel(model_id=embed_dropdown.value, model_version=embed_model_version)\n",
    "embedding_predictor = embedding_model.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0519edac-00a5-40c1-956a-db45aa632073",
   "metadata": {},
   "source": [
    "### deploy meta-llama/Llama-2-13b-hf from Jumpstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cf845-b331-4ed0-a05b-eaa3c2db7ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SageMaker JumpStart provides APIs as part of SageMaker SDK that allow you to deploy and fine-tune models in network isolation using scripts that SageMaker maintains.\n",
    "\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "\n",
    "model = JumpStartModel(model_id=\"meta-textgeneration-llama-2-13b\")\n",
    "example_payloads = model.retrieve_all_examples()\n",
    "\n",
    "# You must manually accept the end-user license agreement (EULA) to deploy the model.\n",
    "# accept_eula = False\n",
    "accept_eula = True\n",
    "\n",
    "if accept_eula:\n",
    "    predictor = model.deploy(accept_eula=accept_eula)\n",
    "\n",
    "    for payload in example_payloads:\n",
    "        response = predictor.predict(payload.body)\n",
    "        prompt = payload.body[payload.prompt_key]\n",
    "        generated_text = response[0][\"generated_text\"]\n",
    "        print(\"\\nInput\\n\", prompt, \"\\n\\nOutput\\n\\n\", generated_text, \"\\n\\n===============\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b56708-2576-4a31-a306-b50b469a6055",
   "metadata": {},
   "source": [
    "## Select desired LLM from deployed endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba519259-257d-4d93-82d0-0cc8af68ff32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available SageMaker Endpoints:\n",
      "1. meta-textgeneration-llama-2-13b-2024-01-15-04-27-30-881\n",
      "2. huggingface-pytorch-tgi-inference-2024-01-15-03-52-46-512\n",
      "3. hf-llm-mistral-7b-2024-01-12-22-18-38-063\n",
      "4. opensearch-gen-ai-llm-falcon-7b-bf16-acf36e80\n",
      "5. opensearch-gen-ai-embedding-gpt-j-6b-acf36e80\n",
      "6. RagEnginesSageMakerModelMultiAB24AEndpoint6DA7D681-7QzzdmVCz76E\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the number for the LLM model endpoint:  3\n",
      "Select the number for the Embedding model endpoint:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected LLM Endpoint: hf-llm-mistral-7b-2024-01-12-22-18-38-063\n",
      "Selected Embedding Endpoint: opensearch-gen-ai-embedding-gpt-j-6b-acf36e80\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "\n",
    "def list_sagemaker_endpoints():\n",
    "    try:\n",
    "        # Create a SageMaker client\n",
    "        sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "        # List SageMaker endpoints\n",
    "        response = sagemaker_client.list_endpoints(\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "\n",
    "        return [endpoint['EndpointName'] for endpoint in response.get('Endpoints', [])]\n",
    "\n",
    "    except NoCredentialsError:\n",
    "        print(\"No AWS credentials found. Please configure your AWS credentials.\")\n",
    "        return []\n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "def select_endpoints(all_endpoints):\n",
    "    print(\"Available SageMaker Endpoints:\")\n",
    "    for i, endpoint in enumerate(all_endpoints, 1):\n",
    "        print(f\"{i}. {endpoint}\")\n",
    "\n",
    "    llm_index = int(input(\"Select the number for the LLM model endpoint: \")) - 1\n",
    "    embedding_index = int(input(\"Select the number for the Embedding model endpoint: \")) - 1\n",
    "\n",
    "    return all_endpoints[llm_index], all_endpoints[embedding_index]\n",
    "\n",
    "# List all available endpoints\n",
    "all_endpoints = list_sagemaker_endpoints()\n",
    "\n",
    "# Let the user select the LLM and Embedding endpoints\n",
    "if all_endpoints:\n",
    "    llm_endpoint_name, embedding_endpoint_name = select_endpoints(all_endpoints)\n",
    "    print(f\"Selected LLM Endpoint: {llm_endpoint_name}\")\n",
    "    print(f\"Selected Embedding Endpoint: {embedding_endpoint_name}\")\n",
    "else:\n",
    "    print(\"No endpoints available to select.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3197fdfe-7626-4517-b0d5-aa52746c5630",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 2. Download and explore ARXIV Metadata dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d94f4b4-174d-4fb3-a57d-b88f83b9c3bf",
   "metadata": {},
   "source": [
    "links:\n",
    "\n",
    "- https://huggingface.co/datasets/arxiv_dataset\n",
    "\n",
    "- https://www.kaggle.com/datasets/Cornell-University/arxiv?resource=download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10679a67-b2c4-4dd9-9285-b7ede10f1946",
   "metadata": {},
   "source": [
    "### Download arxiv dataset from S3 (using cloudfront as a CDN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b772e8-e4fd-47c0-88ba-423737d6add0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File successfully downloaded to arxiv/archive.zip\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "def download_large_file(url, destination):\n",
    "    \"\"\"\n",
    "    Downloads a file from a given URL in chunks and saves it to a destination file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create directory if it does not exist\n",
    "    os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "    \n",
    "    with requests.get(url, stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        with open(destination, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192): \n",
    "                # If you have a chunk, write it to file\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "    return destination\n",
    "\n",
    "# URL of the large file\n",
    "url = 'https://d3bd8cre3dxl8.cloudfront.net/archive.zip'\n",
    "\n",
    "# Destination file path\n",
    "destination = 'arxiv/archive.zip'\n",
    "\n",
    "# Download the file\n",
    "try:\n",
    "    download_large_file(url, destination)\n",
    "    print(f'File successfully downloaded to {destination}')\n",
    "except Exception as e:\n",
    "    print(f'An error occurred: {e}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6588e0e5-8f58-4f02-a9fa-7a0b5a82dfb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17ee605-1388-40e5-89f7-07c7f8ece7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File extracted to arxiv/arxiv-metadata-oai-snapshot.json\n",
      "Time taken: 49.61 seconds\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import time\n",
    "\n",
    "# start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Path to the downloaded zip file\n",
    "zip_file_path = 'arxiv/archive.zip'\n",
    "\n",
    "# Directory to save the extracted file\n",
    "output_dir = 'arxiv'\n",
    "output_file = 'arxiv-metadata-oai-snapshot.json'\n",
    "\n",
    "# Unzip the file\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    zip_ref.extract(output_file, output_dir)\n",
    "\n",
    "print(f'File extracted to {output_dir}/{output_file}')\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(\"Time taken: {:.2f} seconds\".format(duration))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0c470a-899c-4488-b5fc-7b41b33b51ab",
   "metadata": {},
   "source": [
    "### Alternate Download (Optional - No need to repeat if above worked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aced2597-dcf4-47c8-9dd1-6d99e6aac11e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-05 21:01:59    3.7 GiB arxiv-metadata-oai-snapshot.json\n",
      "\n",
      "Total Objects: 1\n",
      "   Total Size: 3.7 GiB\n"
     ]
    }
   ],
   "source": [
    "# uses private AWS account public S3 bucket\n",
    "!aws s3 ls --no-sign-request s3://0-arxiv-dataset/ --human-readable --summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "015194e9-1ef1-45d0-ac16-872af526af6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://0-arxiv-dataset/arxiv-metadata-oai-snapshot.json to arxiv/arxiv-metadata-oai-snapshot.json\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --no-sign-request s3://0-arxiv-dataset/arxiv-metadata-oai-snapshot.json ./arxiv/arxiv-metadata-oai-snapshot.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714c84e-367b-4383-b9b3-405e98c328b7",
   "metadata": {},
   "source": [
    "### Explore the dataset and load into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d95041-eaca-424f-9099-f4a7722f3e54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Entry:\n",
      " id                                                        0704.0001\n",
      "submitter                                            Pavel Nadolsky\n",
      "authors           C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...\n",
      "title             Calculation of prompt diphoton production cros...\n",
      "comments                    37 pages, 15 figures; published version\n",
      "journal-ref                                Phys.Rev.D76:013009,2007\n",
      "doi                                      10.1103/PhysRevD.76.013009\n",
      "report-no                                          ANL-HEP-PR-07-12\n",
      "categories                                                   hep-ph\n",
      "license                                                        None\n",
      "abstract            A fully differential calculation in perturba...\n",
      "versions          [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...\n",
      "update_date                                              2008-11-26\n",
      "authors_parsed    [[Balázs, C., ], [Berger, E. L., ], [Nadolsky,...\n",
      "Name: 0, dtype: object\n",
      "Total Entries: 2393174\n",
      "Max Abstract Length: 6091\n",
      "Time taken: 123.29 seconds\n"
     ]
    }
   ],
   "source": [
    "# takes about 120 seconds with ml.t3.2xlarge\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def process_arxiv_data_pandas(file_path):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Read the data line by line\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "\n",
    "    # Show a sample entry\n",
    "    sample_entry = df.iloc[0]\n",
    "    print(\"Sample Entry:\\n\", sample_entry)\n",
    "\n",
    "    # Compute the number of entries\n",
    "    num_entries = df.shape[0]\n",
    "    print(\"Total Entries:\", num_entries)\n",
    "\n",
    "    # Compute the maximum length of the abstracts\n",
    "    max_abstract_length = df['abstract'].str.len().max()\n",
    "    print(\"Max Abstract Length:\", max_abstract_length)\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(\"Time taken: {:.2f} seconds\".format(duration))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Usage\n",
    "df = process_arxiv_data_pandas('arxiv/arxiv-metadata-oai-snapshot.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276bf81b-750e-421b-8e0e-149214eb1115",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. Create & Deploy Opensearch Service and Vector Index\n",
    "\n",
    "Opensearch is a fork of the popular ElasticSearch and can be used as a vector database that supports knn search.\n",
    "\n",
    "https://opensearch.org/docs/latest/search-plugins/knn/index/\n",
    "https://docs.aws.amazon.com/opensearch-service/latest/developerguide/knn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e0275-a0ac-4b42-afe3-32618e271bc3",
   "metadata": {},
   "source": [
    "## Create Domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b64a98-d36b-405f-8bce-69fd6aec478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain my-opensearch-domain3 created.\n",
      "Domain creation initiated:\n",
      " {\n",
      "    \"ResponseMetadata\": {\n",
      "        \"RequestId\": \"2bc5be72-7e97-4ce2-b6c1-68f4587ed67f\",\n",
      "        \"HTTPStatusCode\": 200,\n",
      "        \"HTTPHeaders\": {\n",
      "            \"x-amzn-requestid\": \"2bc5be72-7e97-4ce2-b6c1-68f4587ed67f\",\n",
      "            \"content-type\": \"application/json\",\n",
      "            \"content-length\": \"2730\",\n",
      "            \"date\": \"Tue, 16 Jan 2024 21:26:04 GMT\"\n",
      "        },\n",
      "        \"RetryAttempts\": 0\n",
      "    },\n",
      "    \"DomainStatus\": {\n",
      "        \"DomainId\": \"730335522976/my-opensearch-domain3\",\n",
      "        \"DomainName\": \"my-opensearch-domain3\",\n",
      "        \"ARN\": \"arn:aws:es:us-east-1:730335522976:domain/my-opensearch-domain3\",\n",
      "        \"Created\": true,\n",
      "        \"Deleted\": false,\n",
      "        \"Processing\": true,\n",
      "        \"UpgradeProcessing\": false,\n",
      "        \"EngineVersion\": \"OpenSearch_2.11\",\n",
      "        \"ClusterConfig\": {\n",
      "            \"InstanceType\": \"c5.large.search\",\n",
      "            \"InstanceCount\": 1,\n",
      "            \"DedicatedMasterEnabled\": false,\n",
      "            \"ZoneAwarenessEnabled\": false,\n",
      "            \"WarmEnabled\": false,\n",
      "            \"ColdStorageOptions\": {\n",
      "                \"Enabled\": false\n",
      "            },\n",
      "            \"MultiAZWithStandbyEnabled\": false\n",
      "        },\n",
      "        \"EBSOptions\": {\n",
      "            \"EBSEnabled\": true,\n",
      "            \"VolumeType\": \"gp2\",\n",
      "            \"VolumeSize\": 10\n",
      "        },\n",
      "        \"AccessPolicies\": \"{\\\"Version\\\":\\\"2012-10-17\\\",\\\"Statement\\\":[{\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"AWS\\\":\\\"arn:aws:sts::730335522976:assumed-role/AmazonSageMaker-ExecutionRole-20240105T122521/SageMaker\\\"},\\\"Action\\\":\\\"es:*\\\",\\\"Resource\\\":\\\"arn:aws:es:us-east-1:730335522976:domain/my-opensearch-domain3/*\\\"},{\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"Service\\\":\\\"sagemaker.amazonaws.com\\\"},\\\"Action\\\":\\\"es:ESHttp*\\\",\\\"Resource\\\":\\\"arn:aws:es:us-east-1:730335522976:domain/my-opensearch-domain3/*\\\"}]}\",\n",
      "        \"IPAddressType\": \"ipv4\",\n",
      "        \"SnapshotOptions\": {\n",
      "            \"AutomatedSnapshotStartHour\": 0\n",
      "        },\n",
      "        \"CognitoOptions\": {\n",
      "            \"Enabled\": false\n",
      "        },\n",
      "        \"EncryptionAtRestOptions\": {\n",
      "            \"Enabled\": true,\n",
      "            \"KmsKeyId\": \"arn:aws:kms:us-east-1:730335522976:key/653cfd47-13be-4dfb-83ff-0c1afc152111\"\n",
      "        },\n",
      "        \"NodeToNodeEncryptionOptions\": {\n",
      "            \"Enabled\": true\n",
      "        },\n",
      "        \"AdvancedOptions\": {\n",
      "            \"override_main_response_version\": \"false\",\n",
      "            \"rest.action.multi.allow_explicit_index\": \"true\"\n",
      "        },\n",
      "        \"ServiceSoftwareOptions\": {\n",
      "            \"CurrentVersion\": \"OpenSearch_2_11_R20231113-P2\",\n",
      "            \"NewVersion\": \"\",\n",
      "            \"UpdateAvailable\": false,\n",
      "            \"Cancellable\": false,\n",
      "            \"UpdateStatus\": \"COMPLETED\",\n",
      "            \"Description\": \"There is no software update available for this domain.\",\n",
      "            \"AutomatedUpdateDate\": \"1970-01-01T00:00:00+00:00\",\n",
      "            \"OptionalDeployment\": true\n",
      "        },\n",
      "        \"DomainEndpointOptions\": {\n",
      "            \"EnforceHTTPS\": false,\n",
      "            \"TLSSecurityPolicy\": \"Policy-Min-TLS-1-0-2019-07\",\n",
      "            \"CustomEndpointEnabled\": false\n",
      "        },\n",
      "        \"AdvancedSecurityOptions\": {\n",
      "            \"Enabled\": false,\n",
      "            \"InternalUserDatabaseEnabled\": false,\n",
      "            \"AnonymousAuthEnabled\": false\n",
      "        },\n",
      "        \"AutoTuneOptions\": {\n",
      "            \"State\": \"ENABLED\",\n",
      "            \"UseOffPeakWindow\": false\n",
      "        },\n",
      "        \"ChangeProgressDetails\": {\n",
      "            \"ChangeId\": \"259c3d80-8838-4398-ba0a-09d00496267a\"\n",
      "        },\n",
      "        \"OffPeakWindowOptions\": {\n",
      "            \"Enabled\": true,\n",
      "            \"OffPeakWindow\": {\n",
      "                \"WindowStartTime\": {\n",
      "                    \"Hours\": 3,\n",
      "                    \"Minutes\": 0\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"SoftwareUpdateOptions\": {\n",
      "            \"AutoSoftwareUpdateEnabled\": false\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "class DateTimeEncoder(json.JSONEncoder):\n",
    "    \"\"\" Custom encoder for encoding datetime objects for JSON serialization. \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, datetime):\n",
    "            return obj.isoformat()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "def create_opensearch_domain(domain_name, instance_type, instance_count, volume_size):\n",
    "    client = boto3.client('opensearch')\n",
    "    sts_client = boto3.client('sts')\n",
    "    region = boto3.session.Session().region_name\n",
    "\n",
    "    # Get AWS account ID and user ARN\n",
    "    identity_info = sts_client.get_caller_identity()\n",
    "    account_id = identity_info[\"Account\"]\n",
    "    user_arn = identity_info[\"Arn\"]\n",
    "\n",
    "    # Define an access policy with the current user's ARN\n",
    "    access_policy = {\n",
    "        \"Version\": \"2012-10-17\",\n",
    "        \"Statement\": [\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"AWS\": user_arn\n",
    "                },\n",
    "                \"Action\": \"es:*\",\n",
    "                \"Resource\": f\"arn:aws:es:{region}:{account_id}:domain/{domain_name}/*\"\n",
    "            },\n",
    "            # Additional statements for other services like SageMaker\n",
    "            {\n",
    "                \"Effect\": \"Allow\",\n",
    "                \"Principal\": {\n",
    "                    \"Service\": \"sagemaker.amazonaws.com\"\n",
    "                },\n",
    "                \"Action\": \"es:ESHttp*\",\n",
    "                \"Resource\": f\"arn:aws:es:{region}:{account_id}:domain/{domain_name}/*\"\n",
    "            }\n",
    "            # ... additional statements as needed ...\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = client.create_domain(\n",
    "            DomainName=domain_name,\n",
    "            EngineVersion='OpenSearch_2.11',  # Specify your desired version\n",
    "            ClusterConfig={\n",
    "                'InstanceType': instance_type,\n",
    "                'InstanceCount': instance_count,\n",
    "                'DedicatedMasterEnabled': False,\n",
    "                'ZoneAwarenessEnabled': False,\n",
    "            },\n",
    "            EBSOptions={\n",
    "                'EBSEnabled': True,\n",
    "                'VolumeType': 'gp2',\n",
    "                'VolumeSize': volume_size,\n",
    "            },\n",
    "            AccessPolicies=json.dumps(access_policy),\n",
    "            NodeToNodeEncryptionOptions={\n",
    "                'Enabled': True\n",
    "            },\n",
    "            EncryptionAtRestOptions={\n",
    "                'Enabled': True\n",
    "            }\n",
    "        )\n",
    "        print(f\"Domain {domain_name} created.\")\n",
    "        return response\n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "domain_name = 'my-opensearch-domain'\n",
    "instance_type = 'c5.large.search'  # Example instance type\n",
    "instance_count = 1\n",
    "volume_size = 10  # in GB\n",
    "\n",
    "response = create_opensearch_domain(domain_name, instance_type, instance_count, volume_size)\n",
    "\n",
    "if response:\n",
    "    # Use the custom DateTimeEncoder for json.dumps\n",
    "    pretty_response = json.dumps(response, indent=4, cls=DateTimeEncoder)\n",
    "    print(\"Domain creation initiated:\\n\", pretty_response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522a6766-68c8-4f38-978d-ae6c529d4292",
   "metadata": {},
   "source": [
    "## Check Opensearch Domain Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb450bda-8943-403b-91b4-db7125eb4ec3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching list of OpenSearch domains...\n",
      "Available OpenSearch Domains:\n",
      "1. opensearchservi-28hd2an8kq9o\n",
      "2. my-opensearch-domain3\n",
      "3. my-opensearch-domain\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the number of the domain you want to check:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is still being set up. Checking again in 60 seconds.\n",
      "Cluster 'my-opensearch-domain3' is ready!\n",
      "Total time elapsed: 1203.49 seconds\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import time\n",
    "\n",
    "def list_opensearch_domains(client):\n",
    "    response = client.list_domain_names()\n",
    "    domain_names = [domain['DomainName'] for domain in response['DomainNames']]\n",
    "    return domain_names\n",
    "\n",
    "def check_opensearch_cluster_status(client, cluster_name):\n",
    "    start_time = time.time()\n",
    "\n",
    "    while True:\n",
    "        response = client.describe_domain(DomainName=cluster_name)\n",
    "        status = response['DomainStatus']['Processing']\n",
    "\n",
    "        if not status:\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f\"Cluster '{cluster_name}' is ready!\")\n",
    "            print(f\"Total time elapsed: {elapsed_time:.2f} seconds\")\n",
    "            break\n",
    "        else:\n",
    "            print(f\"Cluster '{cluster_name}' is still being set up. Checking again in 60 seconds.\")\n",
    "            time.sleep(60)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    client = boto3.client('opensearch')\n",
    "\n",
    "    print(\"Fetching list of OpenSearch domains...\")\n",
    "    domains = list_opensearch_domains(client)\n",
    "\n",
    "    if domains:\n",
    "        print(\"Available OpenSearch Domains:\")\n",
    "        for idx, domain in enumerate(domains, start=1):\n",
    "            print(f\"{idx}. {domain}\")\n",
    "\n",
    "        choice = int(input(\"Enter the number of the domain you want to check: \")) - 1\n",
    "\n",
    "        if 0 <= choice < len(domains):\n",
    "            selected_domain = domains[choice]\n",
    "            check_opensearch_cluster_status(client, selected_domain)\n",
    "        else:\n",
    "            print(\"Invalid selection.\")\n",
    "    else:\n",
    "        print(\"No OpenSearch domains available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5368f0a9-b86f-4e3b-9397-b3f68f29f989",
   "metadata": {},
   "source": [
    "## Retrieve Opensearch Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3232e29-2328-4eac-bb45-f0aa15ef134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "def list_opensearch_domains():\n",
    "    client = boto3.client('opensearch')\n",
    "\n",
    "    domain_summary = []\n",
    "\n",
    "    try:\n",
    "        # List all domain names\n",
    "        domain_names_response = client.list_domain_names()\n",
    "        domain_names = [domain_info['DomainName'] for domain_info in domain_names_response['DomainNames']]\n",
    "\n",
    "        for domain_name in domain_names:\n",
    "            # Describe each domain\n",
    "            domain_response = client.describe_domain(DomainName=domain_name)\n",
    "            domain_status = domain_response['DomainStatus']\n",
    "\n",
    "            # Determine domain operational status\n",
    "            if domain_status.get('Created', False) and not domain_status.get('Deleted', False):\n",
    "                if domain_status.get('Processing', False):\n",
    "                    operational_status = 'Waiting'\n",
    "                else:\n",
    "                    operational_status = 'Ready'\n",
    "            else:\n",
    "                operational_status = 'Not available or deleted'\n",
    "\n",
    "            # Get endpoint information\n",
    "            endpoint = domain_status.get('Endpoint') or domain_status.get('Endpoints', 'Not available')\n",
    "\n",
    "            # Store domain summary information\n",
    "            domain_summary.append({\n",
    "                \"Domain Name\": domain_name,\n",
    "                \"Status\": operational_status,\n",
    "                \"Endpoint\": endpoint\n",
    "            })\n",
    "\n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return\n",
    "\n",
    "    # Display the summary as a formatted table\n",
    "    print(f\"{'Domain Name':30s} {'Status':20s} {'Endpoint'}\")\n",
    "    print('-' * 80)  # Print a separator line\n",
    "    for domain in domain_summary:\n",
    "        print(f\"{domain['Domain Name']:30s} {domain['Status']:20s} {domain['Endpoint']}\")\n",
    "        aos_host = domain['Endpoint']\n",
    "    return aos_host\n",
    "\n",
    "# Example usage\n",
    "aos_host = list_opensearch_domains()\n",
    "print(\"aos_host:\", aos_host)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32554ec3-b26a-44b4-8cf6-9fc5653644ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create an OpenSearch cluster connection.\n",
    "Next, we'll use Python API to set up connection with Amazon Opensearch Service domain.\n",
    "\n",
    "Note: if you're using a region other than us-east-1, please update the region in the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "969caee5-96ed-4cc9-83f1-552ac373735f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search-my-opensearch-domain-nnbajtgulf76kasehvbmxzzjbu.us-east-1.es.amazonaws.com\n",
      "<OpenSearch([{'host': 'search-my-opensearch-domain-nnbajtgulf76kasehvbmxzzjbu.us-east-1.es.amazonaws.com', 'port': 443}])>\n"
     ]
    }
   ],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "import boto3\n",
    "\n",
    "print (aos_host)\n",
    "\n",
    "def create_opensearch_connection(aos_host, region='us-east-1'):\n",
    "    \"\"\"\n",
    "    Create a connection to an OpenSearch cluster from AWS SageMaker Studio.\n",
    "\n",
    "    :param aos_host: The hostname of the OpenSearch cluster.\n",
    "    :param region: AWS region where the OpenSearch cluster is located. Default is 'us-east-1'.\n",
    "    :return: An OpenSearch client object.\n",
    "    \"\"\"\n",
    "    # Retrieve AWS credentials automatically\n",
    "    credentials = boto3.Session().get_credentials()\n",
    "    auth = AWSV4SignerAuth(credentials, region)\n",
    "\n",
    "    aos_client = OpenSearch(\n",
    "        hosts=[{'host': aos_host, 'port': 443}],\n",
    "        http_auth=auth,\n",
    "        use_ssl=True,\n",
    "        verify_certs=True,\n",
    "        connection_class=RequestsHttpConnection\n",
    "    )\n",
    "\n",
    "    return aos_client\n",
    "\n",
    "# Example usage\n",
    "# aos_host = 'your-opensearch-cluster-endpoint'\n",
    "aos_client = create_opensearch_connection(aos_host)\n",
    "print(aos_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b43fc0-ff28-4363-a4fd-2c4356c2c458",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define and create an index in Amazon Opensearch Service \n",
    "We are defining an index with english analyzer which will strip the common stopwords like `the`, `is`, `a`, `an`, etc..\n",
    "\n",
    "We will use the aos_client connection we initiated ealier to create an index in Amazon OpenSearch Service\n",
    "\n",
    "We'll define the index with 4 fields: the first field 'knn_vector' holds the vector representation of the abstract, the second is the \"title\", third field is \"categories\", and fourth is \"update_date\".\n",
    "\n",
    "To create the index, we first define the index in JSON, then use the aos_client connection we initiated ealier to create the index in OpenSearch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a74edf-f284-440c-bb4e-46ed0eeec0f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Define index with GPT-J-6b embeddings (4096 dimensions in vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac1a790-4126-4a61-9e10-d7b13e9edd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.space_type\": \"cosinesimil\",\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"default\": {\n",
    "                    \"type\": \"standard\",\n",
    "                    \"stopwords\": \"_english_\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"abstract_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 4096,\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"categories\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"update_date\": {\n",
    "                \"type\": \"date\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"abstract\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff46cce-057e-45ea-b324-da62d5f84b1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### (Optional - skip if using different Embedding) Define index with BERT embeddings (658 dimensions in vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "835a0406-fecb-4b58-9fa0-1742f7ce76b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.space_type\": \"cosinesimil\",\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"default\": {\n",
    "                    \"type\": \"standard\",\n",
    "                    \"stopwords\": \"_english_\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"abstract_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 768,\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"categories\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"update_date\": {\n",
    "                \"type\": \"date\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae0cc6c-2d28-4ea8-8f98-4197a62adac4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### (Optional - skip if using different Embedding) Define Index with Titan Embeddings (1536 dimensions in vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6d36ba4-c924-4cc8-a18d-9be31761ffd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1536\n",
    "knn_index = {\n",
    "    \"settings\": {\n",
    "        \"index.knn\": True,\n",
    "        \"index.knn.space_type\": \"cosinesimil\",\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"default\": {\n",
    "                    \"type\": \"standard\",\n",
    "                    \"stopwords\": \"_english_\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"abstract_vector\": {\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1536,\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"title\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"categories\": {\n",
    "                \"type\": \"text\",\n",
    "                \"store\": True\n",
    "            },\n",
    "            \"update_date\": {\n",
    "                \"type\": \"date\",\n",
    "                \"store\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c96db27-d3bd-4917-afef-7b2e0c9397e0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create index in Opensearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5396ed9a-0b14-427e-bb85-d99c57eb01bf",
   "metadata": {},
   "source": [
    "If for any reason you need to recreate your dataset, you can uncomment and execute the following to delete any previously created indexes. If this is the first time you're running this, you can skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad163a18-2790-41bd-937e-eff3dcb993c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aos_client.indices.delete(index=\"metadata_arxiv\")\n",
    "# df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6201a20-3d0a-4f8d-b7b4-0b75567c5271",
   "metadata": {},
   "source": [
    "Using the above index definition, we now need to create the index in Amazon OpenSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46c0b93c-1baa-4434-9fc5-ec0d4e0692bf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'metadata_arxiv'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"metadata_arxiv\"\n",
    "aos_client.indices.create(index=index_name,body=knn_index,ignore=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b9f7a-382d-4e5d-b282-7bba7ae7c86c",
   "metadata": {},
   "source": [
    "Let's verify the created index information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ada715-71cd-42b1-a913-522ceb81d2c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata_arxiv': {'aliases': {},\n",
       "  'mappings': {'properties': {'abstract': {'type': 'text', 'store': True},\n",
       "    'abstract_vector': {'type': 'knn_vector',\n",
       "     'store': True,\n",
       "     'dimension': 4096},\n",
       "    'categories': {'type': 'text', 'store': True},\n",
       "    'title': {'type': 'text', 'store': True},\n",
       "    'update_date': {'type': 'date', 'store': True}}},\n",
       "  'settings': {'index': {'replication': {'type': 'DOCUMENT'},\n",
       "    'number_of_shards': '5',\n",
       "    'provided_name': 'metadata_arxiv',\n",
       "    'knn.space_type': 'cosinesimil',\n",
       "    'knn': 'true',\n",
       "    'creation_date': '1705293837108',\n",
       "    'analysis': {'analyzer': {'default': {'type': 'standard',\n",
       "       'stopwords': '_english_'}}},\n",
       "    'number_of_replicas': '1',\n",
       "    'uuid': 'q-CSBsHAQqaRS7uf_Nv2yQ',\n",
       "    'version': {'created': '136327827'}}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aos_client.indices.get(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0190c89e-dddc-4786-900a-1f6982980653",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 4. Generate embeddings of the Article's abstract\n",
    "\n",
    "Lets try GPT-J-6b embeddings to generate vector representations of the abstract data for each article\n",
    "\n",
    "Please note that GPT-J-6b only allows 2048 tokens and out maximimum abstract length was 6091 characters, where a token can be:\n",
    "1. Whole words: Especially for common words.\n",
    "2. Subwords or parts of words: For less common words, which might be broken down into smaller, more frequent subwords.\n",
    "3. Individual characters: Particularly for rare words or unusual character combinations that aren't captured by whole words or subwords in the model's vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d42e99c-2865-435b-925e-d1f41fbd456e",
   "metadata": {},
   "source": [
    "## Employ Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0a3af8-1a70-4a46-b9dd-4a30f7afd40a",
   "metadata": {},
   "source": [
    "### List SageMaker Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbb5ee1-5588-454e-8777-c5099e88539d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current AWS Region: us-east-1\n",
      "Available SageMaker Endpoints:\n",
      "1. meta-textgeneration-llama-2-13b-2024-01-15-04-27-30-881\n",
      "2. huggingface-pytorch-tgi-inference-2024-01-15-03-52-46-512\n",
      "3. hf-llm-mistral-7b-2024-01-12-22-18-38-063\n",
      "4. opensearch-gen-ai-llm-falcon-7b-bf16-acf36e80\n",
      "5. opensearch-gen-ai-embedding-gpt-j-6b-acf36e80\n",
      "6. RagEnginesSageMakerModelMultiAB24AEndpoint6DA7D681-7QzzdmVCz76E\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the number for the LLM model endpoint:  1\n",
      "Select the number for the Embedding model endpoint:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected LLM Endpoint: meta-textgeneration-llama-2-13b-2024-01-15-04-27-30-881\n",
      "Selected Embedding Endpoint: opensearch-gen-ai-embedding-gpt-j-6b-acf36e80\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "\n",
    "# Get the current AWS region\n",
    "aws_region = boto3.session.Session().region_name\n",
    "print(f\"Current AWS Region: {aws_region}\")\n",
    "\n",
    "def list_sagemaker_endpoints():\n",
    "    try:\n",
    "        # Create a SageMaker client\n",
    "        sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "        # List SageMaker endpoints\n",
    "        response = sagemaker_client.list_endpoints(\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "\n",
    "        return [endpoint['EndpointName'] for endpoint in response.get('Endpoints', [])]\n",
    "\n",
    "    except NoCredentialsError:\n",
    "        print(\"No AWS credentials found. Please configure your AWS credentials.\")\n",
    "        return []\n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "def select_endpoints(all_endpoints):\n",
    "    print(\"Available SageMaker Endpoints:\")\n",
    "    for i, endpoint in enumerate(all_endpoints, 1):\n",
    "        print(f\"{i}. {endpoint}\")\n",
    "\n",
    "    llm_index = int(input(\"Select the number for the LLM model endpoint: \")) - 1\n",
    "    embedding_index = int(input(\"Select the number for the Embedding model endpoint: \")) - 1\n",
    "\n",
    "    return all_endpoints[llm_index], all_endpoints[embedding_index]\n",
    "\n",
    "# List all available endpoints\n",
    "all_endpoints = list_sagemaker_endpoints()\n",
    "\n",
    "# Let the user select the LLM and Embedding endpoints\n",
    "if all_endpoints:\n",
    "    llm_endpoint_name, embedding_endpoint_name = select_endpoints(all_endpoints)\n",
    "    print(f\"Selected LLM Endpoint: {llm_endpoint_name}\")\n",
    "    print(f\"Selected Embedding Endpoint: {embedding_endpoint_name}\")\n",
    "else:\n",
    "    print(\"No endpoints available to select.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed30eb0-2c5b-496d-87f7-20f1efdeef72",
   "metadata": {},
   "source": [
    "## Lets try vectorizing the abstract on a subset of 1000 articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e4b84a-7f2f-4bca-91b3-e9c9eb0e5eee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using GPT-J-6B (max 2048 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5254029a-70e9-4079-bcc8-d12adf92df2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opensearch-gen-ai-embedding-gpt-j-6b-acf36e80\n",
      "us-east-1\n",
      "Vectorized Abstracts Successfully\n",
      "Time taken for vectorization: 92.34969973564148 seconds\n",
      "0      [0.007603085599839687, 0.004107543732970953, 0...\n",
      "1      [0.006115400698035955, 0.0024362001568078995, ...\n",
      "2      [0.016317538917064667, -0.003693857230246067, ...\n",
      "3      [0.009021581150591373, -0.011483951471745968, ...\n",
      "4      [0.00858279038220644, -0.0020114851649850607, ...\n",
      "                             ...                        \n",
      "995    [-0.0017040536040440202, 0.01018516719341278, ...\n",
      "996    [0.020026983693242073, 0.008944433182477951, -...\n",
      "997    [0.0017824446549639106, 0.0012971345568075776,...\n",
      "998    [-0.014983518049120903, 0.00807292852550745, 0...\n",
      "999    [0.014853671193122864, 0.010220940224826336, 0...\n",
      "Name: abstract, Length: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 1000 articles in ~92 seconds\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "\n",
    "no_of_articles = 1000\n",
    "start_time = time.time()\n",
    "\n",
    "# Name of your SageMaker endpoint\n",
    "# Load or define env variables\n",
    "if embedding_endpoint_name:\n",
    "    print(embedding_endpoint_name)\n",
    "else:\n",
    "    embedding_endpoint_name = \"your-sagemaker-endpoint-name\"\n",
    "    \n",
    "if aws_region:\n",
    "    print(aws_region)\n",
    "else:\n",
    "    aws_region = \"your-aws-region\"\n",
    "\n",
    "# Establish a connection to the SageMaker runtime\n",
    "client = boto3.client('runtime.sagemaker', region_name=aws_region)\n",
    "\n",
    "def vectorize_text_sagemaker(text):\n",
    "    # Prepare the payload with the expected parameter names\n",
    "    payload = json.dumps({\"text_inputs\": text})  # text should already be a list of strings\n",
    "\n",
    "    # Sending the text to the SageMaker endpoint\n",
    "    response = client.invoke_endpoint(EndpointName=embedding_endpoint_name,\n",
    "                                      ContentType='application/json',\n",
    "                                      Body=payload)\n",
    "    # Receiving the response and converting it\n",
    "    response_body = json.loads(response['Body'].read().decode())\n",
    "    return response_body['embedding'][0]\n",
    "\n",
    "# Select the subset of your DataFrame\n",
    "df_subset = df.head(no_of_articles)\n",
    "\n",
    "# Apply the vectorization function\n",
    "vectorized_abstracts = df_subset['abstract'].apply(vectorize_text_sagemaker)\n",
    "\n",
    "print(\"Vectorized Abstracts Successfully\")\n",
    "\n",
    "end_time = time.time()\n",
    "time_vectorization = end_time - start_time\n",
    "print(f\"Time taken for vectorization: {time_vectorization} seconds\")\n",
    "print(vectorized_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f087cc-c7e6-4814-a4e8-60d47310f9d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using BERT (max 512 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "205a215d-5df9-49c4-8dae-6a06be3f0a09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized Abstracts Successfully\n",
      "Time taken for vectorization: 16.427900075912476 seconds\n",
      "0     [-0.3771481, -0.048133407, 0.34441498, -0.1936...\n",
      "1     [-0.40378582, 0.014585821, 0.15648036, -0.2119...\n",
      "2     [-0.41898176, 0.16085128, 0.643277, -0.0904780...\n",
      "3     [-0.19868158, -0.043408114, 0.02741245, -0.195...\n",
      "4     [-0.12638369, 0.19934435, 0.40047324, -0.39668...\n",
      "                            ...                        \n",
      "95    [-0.40263885, 0.017360615, 0.21860191, -0.2216...\n",
      "96    [-0.35702378, -0.053870752, -0.10470553, -0.47...\n",
      "97    [-0.24074006, -0.13507345, 0.1704656, -0.20295...\n",
      "98    [-0.18630911, 0.1520963, 0.47631258, -0.330984...\n",
      "99    [-0.36923856, -0.0116866045, 0.2750462, -0.330...\n",
      "Name: abstract, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 100 articles takes ~16 seconds\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "no_of_articles = 100\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize the BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def vectorize_text(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "\n",
    "# Vectorize the first 10 abstracts\n",
    "df_subset = df.head(no_of_articles)\n",
    "vectorized_abstracts = df_subset['abstract'].apply(vectorize_text)\n",
    "bert_vectors = vectorized_abstracts\n",
    "print(\"Vectorized Abstracts Successfully\")\n",
    "\n",
    "end_time = time.time()\n",
    "time_vectorization = end_time - start_time\n",
    "print(f\"Time taken for vectorization: {time_vectorization} seconds\")\n",
    "print(vectorized_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea5b41f-11b6-4a62-8627-20e9d06da1ba",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Using Titan Embeddings and Bedrock (8192 max tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961e783e-63a5-4285-84e9-287502a4747f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.33.9\n",
      "Vectorized Abstracts Successfully\n",
      "Time taken for vectorization: 16.373608589172363 seconds\n",
      "0     [0.064941406, 0.77734375, -0.08203125, -0.1796...\n",
      "1     [0.18457031, 0.5234375, 0.080078125, 0.0363769...\n",
      "2     [0.63671875, -0.18457031, 0.17773438, -0.41210...\n",
      "3     [-0.2578125, 0.032226562, -0.16113281, -0.1337...\n",
      "4     [0.390625, 0.171875, -0.09716797, -0.12207031,...\n",
      "                            ...                        \n",
      "95    [-0.010864258, 0.032226562, -0.1171875, -0.218...\n",
      "96    [-0.33203125, 0.22363281, -0.20117188, 0.03857...\n",
      "97    [-0.73828125, -0.06542969, 0.30859375, 0.19042...\n",
      "98    [0.38085938, 0.27539062, -0.39648438, 0.294921...\n",
      "99    [0.5546875, 0.08544922, -0.27148438, -0.057617...\n",
      "Name: abstract, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# 100 articles takes ~16 seconds\n",
    "import os\n",
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "no_of_articles = 100\n",
    "start_time = time.time()\n",
    "\n",
    "print(boto3.__version__)\n",
    "\n",
    "# Initialize AWS Session for Titan Embeddings\n",
    "session = boto3.Session(\n",
    "    profile_name=os.environ.get(\"BWB_PROFILE_NAME\")\n",
    ")\n",
    "bedrock = boto3.client(service_name='bedrock-runtime')\n",
    "\n",
    "def get_titan_embedding(text):\n",
    "    try:\n",
    "        body = json.dumps({\"inputText\": text})\n",
    "        model_id = 'amazon.titan-embed-text-v1'\n",
    "        mime_type = 'application/json'\n",
    "        response = bedrock.invoke_model(body=body, modelId=model_id, accept=mime_type, contentType=mime_type)\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        \n",
    "        # Check if embedding is in the response\n",
    "        if 'embedding' in response_body:\n",
    "            embedding = response_body.get('embedding')\n",
    "            return np.array(embedding)\n",
    "        else:\n",
    "            print(\"Embedding not found in the response\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error in getting Titan embedding: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to vectorize text using Titan Embeddings\n",
    "def vectorize_text(text):\n",
    "    embedding = get_titan_embedding(text)\n",
    "    return np.array(embedding)\n",
    "\n",
    "# Assuming 'df' is a DataFrame with an 'abstract' column\n",
    "df_subset = df.head(no_of_articles)\n",
    "vectorized_abstracts = df_subset['abstract'].apply(get_titan_embedding)\n",
    "titan_vectors = vectorized_abstracts\n",
    "print(\"Vectorized Abstracts Successfully\")\n",
    "\n",
    "end_time = time.time()\n",
    "time_vectorization = end_time - start_time\n",
    "print(f\"Time taken for vectorization: {time_vectorization} seconds\")\n",
    "print(vectorized_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d894e1-41d2-4105-829c-6ea67e156bd3",
   "metadata": {},
   "source": [
    "### Create a new DataFrame with the vectorized abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2a01ef-b2a5-4ab2-9201-1099846abd62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   vectorized_abstract  \\\n",
      "0    [0.007603085599839687, 0.004107543732970953, 0...   \n",
      "1    [0.006115400698035955, 0.0024362001568078995, ...   \n",
      "2    [0.016317538917064667, -0.003693857230246067, ...   \n",
      "3    [0.009021581150591373, -0.011483951471745968, ...   \n",
      "4    [0.00858279038220644, -0.0020114851649850607, ...   \n",
      "..                                                 ...   \n",
      "995  [-0.0017040536040440202, 0.01018516719341278, ...   \n",
      "996  [0.020026983693242073, 0.008944433182477951, -...   \n",
      "997  [0.0017824446549639106, 0.0012971345568075776,...   \n",
      "998  [-0.014983518049120903, 0.00807292852550745, 0...   \n",
      "999  [0.014853671193122864, 0.010220940224826336, 0...   \n",
      "\n",
      "                                                 title       categories  \\\n",
      "0    Calculation of prompt diphoton production cros...           hep-ph   \n",
      "1             Sparsity-certifying Graph Decompositions    math.CO cs.CG   \n",
      "2    The evolution of the Earth-Moon system based o...   physics.gen-ph   \n",
      "3    A determinant of Stirling cycle numbers counts...          math.CO   \n",
      "4    From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...  math.CA math.FA   \n",
      "..                                                 ...              ...   \n",
      "995                            Brane World Black Rings           hep-th   \n",
      "996                Stable algebras of entire functions          math.CV   \n",
      "997  Test vectors for trilinear forms, when two rep...          math.NT   \n",
      "998  Generic character sheaves on disconnected grou...          math.RT   \n",
      "999  Measurement of D0-D0bar mixing in D0->Ks pi+ p...           hep-ex   \n",
      "\n",
      "    update_date                                           abstract  \n",
      "0    2008-11-26    A fully differential calculation in perturba...  \n",
      "1    2008-12-13    We describe a new algorithm, the $(k,\\ell)$-...  \n",
      "2    2008-01-13    The evolution of Earth-Moon system is descri...  \n",
      "3    2007-05-23    We show that a determinant of Stirling cycle...  \n",
      "4    2013-10-15    In this paper we show how to compute the $\\L...  \n",
      "..          ...                                                ...  \n",
      "995  2009-11-13    Five dimensional neutral rotating black ring...  \n",
      "996  2007-05-23    Suppose that $h$ and $g$ belong to the algeb...  \n",
      "997  2007-05-23    Let F be a finite extension of Qp and G be G...  \n",
      "998  2007-05-23    We relate a generic character sheaf on a dis...  \n",
      "999  2019-08-12    We report a measurement of D0-D0bar mixing i...  \n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "Time taken to create new DataFrame: 0.011837244033813477 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "new_df = pd.DataFrame({\n",
    "    'vectorized_abstract': vectorized_abstracts,\n",
    "    'title': df_subset['title'],\n",
    "    'categories': df_subset['categories'],\n",
    "    'update_date': df_subset['update_date'],\n",
    "    'abstract': df_subset['abstract']\n",
    "})\n",
    "\n",
    "print(new_df)\n",
    "\n",
    "end_time = time.time()\n",
    "time_dataframe_creation = end_time - start_time\n",
    "print(f\"Time taken to create new DataFrame: {time_dataframe_creation} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fd9809-2c21-49df-91cd-a15754675a8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Optional: Clean rows with missing or null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7ac7562-7352-4d19-b7f0-fecf04ba28a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   vectorized_abstract  \\\n",
      "0    [0.007603085599839687, 0.004107543732970953, 0...   \n",
      "1    [0.006115400698035955, 0.0024362001568078995, ...   \n",
      "2    [0.016317538917064667, -0.003693857230246067, ...   \n",
      "3    [0.009021581150591373, -0.011483951471745968, ...   \n",
      "4    [0.00858279038220644, -0.0020114851649850607, ...   \n",
      "..                                                 ...   \n",
      "995  [-0.0017040536040440202, 0.01018516719341278, ...   \n",
      "996  [0.020026983693242073, 0.008944433182477951, -...   \n",
      "997  [0.0017824446549639106, 0.0012971345568075776,...   \n",
      "998  [-0.014983518049120903, 0.00807292852550745, 0...   \n",
      "999  [0.014853671193122864, 0.010220940224826336, 0...   \n",
      "\n",
      "                                                 title       categories  \\\n",
      "0    Calculation of prompt diphoton production cros...           hep-ph   \n",
      "1             Sparsity-certifying Graph Decompositions    math.CO cs.CG   \n",
      "2    The evolution of the Earth-Moon system based o...   physics.gen-ph   \n",
      "3    A determinant of Stirling cycle numbers counts...          math.CO   \n",
      "4    From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...  math.CA math.FA   \n",
      "..                                                 ...              ...   \n",
      "995                            Brane World Black Rings           hep-th   \n",
      "996                Stable algebras of entire functions          math.CV   \n",
      "997  Test vectors for trilinear forms, when two rep...          math.NT   \n",
      "998  Generic character sheaves on disconnected grou...          math.RT   \n",
      "999  Measurement of D0-D0bar mixing in D0->Ks pi+ p...           hep-ex   \n",
      "\n",
      "    update_date                                           abstract  \n",
      "0    2008-11-26    A fully differential calculation in perturba...  \n",
      "1    2008-12-13    We describe a new algorithm, the $(k,\\ell)$-...  \n",
      "2    2008-01-13    The evolution of Earth-Moon system is descri...  \n",
      "3    2007-05-23    We show that a determinant of Stirling cycle...  \n",
      "4    2013-10-15    In this paper we show how to compute the $\\L...  \n",
      "..          ...                                                ...  \n",
      "995  2009-11-13    Five dimensional neutral rotating black ring...  \n",
      "996  2007-05-23    Suppose that $h$ and $g$ belong to the algeb...  \n",
      "997  2007-05-23    Let F be a finite extension of Qp and G be G...  \n",
      "998  2007-05-23    We relate a generic character sheaf on a dis...  \n",
      "999  2019-08-12    We report a measurement of D0-D0bar mixing i...  \n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "Number of rows removed: 0\n",
      "Total remaining rows: 1000\n",
      "Time taken to create and clean new DataFrame: 0.014614343643188477 seconds\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Number of rows before removing missing/null values\n",
    "initial_row_count = new_df.shape[0]\n",
    "\n",
    "# Remove rows with missing or null values\n",
    "cleaned_df = new_df.dropna()\n",
    "\n",
    "# Number of rows after removing missing/null values\n",
    "final_row_count = cleaned_df.shape[0]\n",
    "\n",
    "# Calculate the number of rows removed\n",
    "rows_removed = initial_row_count - final_row_count\n",
    "\n",
    "print(cleaned_df)\n",
    "\n",
    "end_time = time.time()\n",
    "time_dataframe_creation = end_time - start_time\n",
    "\n",
    "print(f\"Number of rows removed: {rows_removed}\")\n",
    "print(f\"Total remaining rows: {final_row_count}\")\n",
    "print(f\"Time taken to create and clean new DataFrame: {time_dataframe_creation} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6906ed84-a1ea-44f3-af35-783e992f462d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 5. Load the Data into OpenSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314025e7-d52e-4f75-9257-a36d2ca02d49",
   "metadata": {},
   "source": [
    "### Should work for all embedding models (GPT-J, BERT, Titan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aae6f06-d772-41ca-b763-5062cce8bb3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 0 documents\n",
      "Indexed 100 documents\n",
      "Indexed 200 documents\n",
      "Indexed 300 documents\n",
      "Indexed 400 documents\n",
      "Indexed 500 documents\n",
      "Indexed 600 documents\n",
      "Indexed 700 documents\n",
      "Indexed 800 documents\n",
      "Indexed 900 documents\n",
      "Time taken to index data in OpenSearch: 23.23329448699951 seconds\n"
     ]
    }
   ],
   "source": [
    "# 1000 records in ~23 seconds\n",
    "start_time = time.time()\n",
    "import numpy as np\n",
    "\n",
    "def index_dataframe(aos_client, index_name, dataframe):\n",
    "    for index, row in dataframe.iterrows():\n",
    "        # Convert to list if it's a numpy array\n",
    "        vector = row['vectorized_abstract']\n",
    "        if isinstance(vector, np.ndarray):\n",
    "            vector = vector.tolist()\n",
    "\n",
    "        # Print the document for the first few rows to debug\n",
    "        # if index < 1:\n",
    "            # print(f\"Document at index {index}: {vector}\")\n",
    "\n",
    "        # Skip if the vector is null or empty\n",
    "        if vector is None or len(vector) == 0:\n",
    "            print(f\"Skipping index {index} due to null or empty vector\")\n",
    "            continue\n",
    "\n",
    "        document = {\n",
    "            \"abstract_vector\": vector,\n",
    "            \"title\": row['title'],\n",
    "            \"categories\": row['categories'],\n",
    "            \"update_date\": row['update_date'],\n",
    "            \"abstract\": row['abstract']\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            aos_client.index(index=index_name, body=document)\n",
    "            if index % 100 == 0:\n",
    "                print(f\"Indexed {index} documents\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error indexing document at index {index}: {e}\")\n",
    "\n",
    "# Example usage\n",
    "index_dataframe(aos_client, index_name, new_df)\n",
    "\n",
    "# timing\n",
    "end_time = time.time()\n",
    "print(f\"Time taken to index data in OpenSearch: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08242771-903b-4248-a972-44733ef53816",
   "metadata": {},
   "source": [
    "### To validate the load, we'll query the number of documents number in the index. We should have 1000 hits in the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0ebfd90-b71a-4110-8d1f-5af2818b19d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records found: 1000.\n"
     ]
    }
   ],
   "source": [
    "res = aos_client.search(index=index_name, body={\"query\": {\"match_all\": {}}})\n",
    "print(\"Records found: %d.\" % res['hits']['total']['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413cf048-3650-4470-878f-166a0f778073",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 6. Return Relevant Semantic Search Results in a scored table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac96a3f-520a-4d6f-bd2f-d52c3a5c62ce",
   "metadata": {},
   "source": [
    "## Generate vector for user input query\n",
    "Next, we'll use the same bert helper function to translate our input question into a vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8b27d0-2221-4893-800c-4da86ddce5bf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GPT-J-6b vectorized Search Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0293ce1-0320-4a93-b707-680467d4a391",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_raw_sentences = ['We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.']\n",
    "# looking for this article: https://arxiv.org/pdf/1706.03762.pdf\n",
    "search_vector = vectorize_text_sagemaker(query_raw_sentences)\n",
    "# search_vector = vectorize_text(query_raw_sentences)[0].tolist()\n",
    "search_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc598c73-cc0a-4d43-b6d2-9b12bfdc99ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BERT vectorized Search Query (Optional - skip if not using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd46104-f605-4ebf-b02b-22e998aa8e93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_raw_sentences = ['We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.']\n",
    "# looking for this article: https://arxiv.org/pdf/1706.03762.pdf\n",
    "search_vector = vectorize_text(query_raw_sentences)\n",
    "# search_vector = vectorize_text(query_raw_sentences)[0].tolist()\n",
    "search_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119aa0f1-d7ef-4992-a5d1-dbdda0627b1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Titan Embedding Search Query ((Optional - skip if not using)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac0d75c-24ab-412a-b970-177e144efc86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17871094 0.01312256 0.55078125 ... 0.2890625  0.75       0.2890625 ]\n"
     ]
    }
   ],
   "source": [
    "# Single sentence as a string\n",
    "query_sentence = 'We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.'\n",
    "# Get embedding for the single sentence\n",
    "search_vector = get_titan_embedding(query_sentence)\n",
    "\n",
    "print(search_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8739cc-5502-4678-903e-e7a22faa46d7",
   "metadata": {},
   "source": [
    "## Search vector with \"Semantic Search\"\n",
    "Now that we have vector in OpenSearch and a vector for our query question, let's perform a KNN search in OpenSearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76f2b3e1-f967-4bdb-9795-c4a37fd0ebdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 150 Hits:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>title</th>\n",
       "      <th>categories</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>odp_C40B7yV8sqPy8FM_</td>\n",
       "      <td>0.774213</td>\n",
       "      <td>Architecture for Pseudo Acausal Evolvable Embe...</td>\n",
       "      <td>cs.NE cs.AI</td>\n",
       "      <td>Advances in semiconductor technology are con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N9p_C40B7yV8sqPy01Ix</td>\n",
       "      <td>0.770050</td>\n",
       "      <td>Algorithm for anisotropic diffusion in hydroge...</td>\n",
       "      <td>cond-mat.soft</td>\n",
       "      <td>In this paper I describe a specialized algor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Btp_C40B7yV8sqPypFDs</td>\n",
       "      <td>0.769617</td>\n",
       "      <td>On-line Viterbi Algorithm and Its Relationship...</td>\n",
       "      <td>cs.DS</td>\n",
       "      <td>In this paper, we introduce the on-line Vite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ttp_C40B7yV8sqPy3FK9</td>\n",
       "      <td>0.769492</td>\n",
       "      <td>Some combinatorial aspects of differential ope...</td>\n",
       "      <td>math.DG math.CA</td>\n",
       "      <td>In this paper we present a recurrent relatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UNp_C40B7yV8sqPy1VIJ</td>\n",
       "      <td>0.769154</td>\n",
       "      <td>Behavioral response to strong aversive stimuli...</td>\n",
       "      <td>q-bio.NC</td>\n",
       "      <td>In this paper a theoretical model of functio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>s9p_C40B7yV8sqPy3FKI</td>\n",
       "      <td>0.768879</td>\n",
       "      <td>A note on higher-order differential operations</td>\n",
       "      <td>math.DG math.CA</td>\n",
       "      <td>In this paper we consider successive iterati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>odp_C40B7yV8sqPyyFFT</td>\n",
       "      <td>0.768208</td>\n",
       "      <td>Contrasting Two Transformation-Based Methods f...</td>\n",
       "      <td>math.OC</td>\n",
       "      <td>In this note we contrast two transformation-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1Np_C40B7yV8sqPytlDW</td>\n",
       "      <td>0.763659</td>\n",
       "      <td>Automated Generation of Layout and Control for...</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>We present a computer-aided design flow for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-9p_C40B7yV8sqPypE8o</td>\n",
       "      <td>0.763191</td>\n",
       "      <td>Visualizing Teleportation</td>\n",
       "      <td>physics.ed-ph quant-ph</td>\n",
       "      <td>A novel way of picturing the processing of q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Htp_C40B7yV8sqPy0VJX</td>\n",
       "      <td>0.761483</td>\n",
       "      <td>Evolutionary Neural Gas (ENG): A Model of Self...</td>\n",
       "      <td>physics.gen-ph q-bio.PE</td>\n",
       "      <td>Despite their claimed biological plausibilit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>udp_C40B7yV8sqPyylEK</td>\n",
       "      <td>0.760641</td>\n",
       "      <td>Penalization approach for mixed hyperbolic sys...</td>\n",
       "      <td>math.AP</td>\n",
       "      <td>In this paper, we describe a new, systematic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>zdp_C40B7yV8sqPyoE8I</td>\n",
       "      <td>0.757722</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>math.CA math.FA</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3Np_C40B7yV8sqPy31KN</td>\n",
       "      <td>0.757624</td>\n",
       "      <td>Optimal Synthesis of Multiple Algorithms</td>\n",
       "      <td>cs.DS cs.PF</td>\n",
       "      <td>In this paper we give a definition of \"algor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q9p_C40B7yV8sqPyv1Hb</td>\n",
       "      <td>0.757318</td>\n",
       "      <td>Capturing knots in polymers</td>\n",
       "      <td>cond-mat.soft cond-mat.stat-mech</td>\n",
       "      <td>This paper visualizes a knot reduction algor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sNp_C40B7yV8sqPy3FJT</td>\n",
       "      <td>0.754881</td>\n",
       "      <td>Quantifying social group evolution</td>\n",
       "      <td>stat.ME physics.soc-ph stat.AP</td>\n",
       "      <td>The rich set of interactions between individ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ldp_C40B7yV8sqPyp1Cz</td>\n",
       "      <td>0.754843</td>\n",
       "      <td>The birth of string theory</td>\n",
       "      <td>hep-th</td>\n",
       "      <td>In this contribution we go through the devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FNp_C40B7yV8sqPy0FKd</td>\n",
       "      <td>0.754066</td>\n",
       "      <td>A new approach to mutual information</td>\n",
       "      <td>math.PR math.ST stat.TH</td>\n",
       "      <td>A new expression as a certain asymptotic lim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dtp_C40B7yV8sqPyu1E-</td>\n",
       "      <td>0.752656</td>\n",
       "      <td>On generalized entropy measures and pathways</td>\n",
       "      <td>math.ST cond-mat.stat-mech stat.TH</td>\n",
       "      <td>Product probability property, known in the l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Idp_C40B7yV8sqPyplDg</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>A general approach to statistical modeling of ...</td>\n",
       "      <td>physics.data-an physics.gen-ph</td>\n",
       "      <td>Statistical modeling of experimental physica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fdp_C40B7yV8sqPyr1D2</td>\n",
       "      <td>0.752639</td>\n",
       "      <td>Genetic Optimization of Photonic Bandgap Struc...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "      <td>We investigate the use of a Genetic Algorith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Ctp_C40B7yV8sqPy41Ms</td>\n",
       "      <td>0.752600</td>\n",
       "      <td>P-adic arithmetic coding</td>\n",
       "      <td>cs.DS</td>\n",
       "      <td>A new incremental algorithm for data compres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>bNp_C40B7yV8sqPyw1Gd</td>\n",
       "      <td>0.752188</td>\n",
       "      <td>The Hourglass - Consequences of Pure Hamiltoni...</td>\n",
       "      <td>quant-ph</td>\n",
       "      <td>Hourglass is the name given here to a formal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2tp_C40B7yV8sqPyt1BX</td>\n",
       "      <td>0.751881</td>\n",
       "      <td>New version announcement for TaylUR, an arbitr...</td>\n",
       "      <td>physics.comp-ph</td>\n",
       "      <td>We present a new version of TaylUR, a Fortra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-Np_C40B7yV8sqPyuVCO</td>\n",
       "      <td>0.751399</td>\n",
       "      <td>The World as Evolving Information</td>\n",
       "      <td>cs.IT cs.AI math.IT q-bio.PE</td>\n",
       "      <td>This paper discusses the benefits of describ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>G9p_C40B7yV8sqPy5FOk</td>\n",
       "      <td>0.751065</td>\n",
       "      <td>Counting on rectangular areas</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>In the first section of this paper we prove ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>69p_C40B7yV8sqPyok-s</td>\n",
       "      <td>0.750998</td>\n",
       "      <td>Convergence of the discrete dipole approximati...</td>\n",
       "      <td>physics.optics physics.comp-ph</td>\n",
       "      <td>We propose an extrapolation technique that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dtp_C40B7yV8sqPy41OF</td>\n",
       "      <td>0.750866</td>\n",
       "      <td>Universal Source Coding for Monotonic and Fast...</td>\n",
       "      <td>cs.IT math.IT</td>\n",
       "      <td>We study universal compression of sequences ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>rNp_C40B7yV8sqPyyVEY</td>\n",
       "      <td>0.750412</td>\n",
       "      <td>Search for Chaotic Behavior in a Flapping Flag</td>\n",
       "      <td>physics.ed-ph physics.gen-ph</td>\n",
       "      <td>We measured the correlation of the times bet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>T9p_C40B7yV8sqPy6VNI</td>\n",
       "      <td>0.750196</td>\n",
       "      <td>New possible properties of atomic nuclei inves...</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "      <td>For the first time we apply the methodologie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>S9p_C40B7yV8sqPyqlAx</td>\n",
       "      <td>0.749744</td>\n",
       "      <td>Vacuum Structure and Potential</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "      <td>Based on overall experimental observations, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     _id    _score  \\\n",
       "0   odp_C40B7yV8sqPy8FM_  0.774213   \n",
       "1   N9p_C40B7yV8sqPy01Ix  0.770050   \n",
       "2   Btp_C40B7yV8sqPypFDs  0.769617   \n",
       "3   ttp_C40B7yV8sqPy3FK9  0.769492   \n",
       "4   UNp_C40B7yV8sqPy1VIJ  0.769154   \n",
       "5   s9p_C40B7yV8sqPy3FKI  0.768879   \n",
       "6   odp_C40B7yV8sqPyyFFT  0.768208   \n",
       "7   1Np_C40B7yV8sqPytlDW  0.763659   \n",
       "8   -9p_C40B7yV8sqPypE8o  0.763191   \n",
       "9   Htp_C40B7yV8sqPy0VJX  0.761483   \n",
       "10  udp_C40B7yV8sqPyylEK  0.760641   \n",
       "11  zdp_C40B7yV8sqPyoE8I  0.757722   \n",
       "12  3Np_C40B7yV8sqPy31KN  0.757624   \n",
       "13  Q9p_C40B7yV8sqPyv1Hb  0.757318   \n",
       "14  sNp_C40B7yV8sqPy3FJT  0.754881   \n",
       "15  Ldp_C40B7yV8sqPyp1Cz  0.754843   \n",
       "16  FNp_C40B7yV8sqPy0FKd  0.754066   \n",
       "17  Dtp_C40B7yV8sqPyu1E-  0.752656   \n",
       "18  Idp_C40B7yV8sqPyplDg  0.752640   \n",
       "19  fdp_C40B7yV8sqPyr1D2  0.752639   \n",
       "20  Ctp_C40B7yV8sqPy41Ms  0.752600   \n",
       "21  bNp_C40B7yV8sqPyw1Gd  0.752188   \n",
       "22  2tp_C40B7yV8sqPyt1BX  0.751881   \n",
       "23  -Np_C40B7yV8sqPyuVCO  0.751399   \n",
       "24  G9p_C40B7yV8sqPy5FOk  0.751065   \n",
       "25  69p_C40B7yV8sqPyok-s  0.750998   \n",
       "26  Dtp_C40B7yV8sqPy41OF  0.750866   \n",
       "27  rNp_C40B7yV8sqPyyVEY  0.750412   \n",
       "28  T9p_C40B7yV8sqPy6VNI  0.750196   \n",
       "29  S9p_C40B7yV8sqPyqlAx  0.749744   \n",
       "\n",
       "                                                title  \\\n",
       "0   Architecture for Pseudo Acausal Evolvable Embe...   \n",
       "1   Algorithm for anisotropic diffusion in hydroge...   \n",
       "2   On-line Viterbi Algorithm and Its Relationship...   \n",
       "3   Some combinatorial aspects of differential ope...   \n",
       "4   Behavioral response to strong aversive stimuli...   \n",
       "5      A note on higher-order differential operations   \n",
       "6   Contrasting Two Transformation-Based Methods f...   \n",
       "7   Automated Generation of Layout and Control for...   \n",
       "8                           Visualizing Teleportation   \n",
       "9   Evolutionary Neural Gas (ENG): A Model of Self...   \n",
       "10  Penalization approach for mixed hyperbolic sys...   \n",
       "11  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "12           Optimal Synthesis of Multiple Algorithms   \n",
       "13                        Capturing knots in polymers   \n",
       "14                 Quantifying social group evolution   \n",
       "15                         The birth of string theory   \n",
       "16               A new approach to mutual information   \n",
       "17       On generalized entropy measures and pathways   \n",
       "18  A general approach to statistical modeling of ...   \n",
       "19  Genetic Optimization of Photonic Bandgap Struc...   \n",
       "20                           P-adic arithmetic coding   \n",
       "21  The Hourglass - Consequences of Pure Hamiltoni...   \n",
       "22  New version announcement for TaylUR, an arbitr...   \n",
       "23                  The World as Evolving Information   \n",
       "24                      Counting on rectangular areas   \n",
       "25  Convergence of the discrete dipole approximati...   \n",
       "26  Universal Source Coding for Monotonic and Fast...   \n",
       "27     Search for Chaotic Behavior in a Flapping Flag   \n",
       "28  New possible properties of atomic nuclei inves...   \n",
       "29                     Vacuum Structure and Potential   \n",
       "\n",
       "                            categories  \\\n",
       "0                          cs.NE cs.AI   \n",
       "1                        cond-mat.soft   \n",
       "2                                cs.DS   \n",
       "3                      math.DG math.CA   \n",
       "4                             q-bio.NC   \n",
       "5                      math.DG math.CA   \n",
       "6                              math.OC   \n",
       "7                             quant-ph   \n",
       "8               physics.ed-ph quant-ph   \n",
       "9              physics.gen-ph q-bio.PE   \n",
       "10                             math.AP   \n",
       "11                     math.CA math.FA   \n",
       "12                         cs.DS cs.PF   \n",
       "13    cond-mat.soft cond-mat.stat-mech   \n",
       "14      stat.ME physics.soc-ph stat.AP   \n",
       "15                              hep-th   \n",
       "16             math.PR math.ST stat.TH   \n",
       "17  math.ST cond-mat.stat-mech stat.TH   \n",
       "18      physics.data-an physics.gen-ph   \n",
       "19      physics.optics physics.comp-ph   \n",
       "20                               cs.DS   \n",
       "21                            quant-ph   \n",
       "22                     physics.comp-ph   \n",
       "23        cs.IT cs.AI math.IT q-bio.PE   \n",
       "24                             math.CO   \n",
       "25      physics.optics physics.comp-ph   \n",
       "26                       cs.IT math.IT   \n",
       "27        physics.ed-ph physics.gen-ph   \n",
       "28                      physics.gen-ph   \n",
       "29                      physics.gen-ph   \n",
       "\n",
       "                                             abstract  \n",
       "0     Advances in semiconductor technology are con...  \n",
       "1     In this paper I describe a specialized algor...  \n",
       "2     In this paper, we introduce the on-line Vite...  \n",
       "3     In this paper we present a recurrent relatio...  \n",
       "4     In this paper a theoretical model of functio...  \n",
       "5     In this paper we consider successive iterati...  \n",
       "6     In this note we contrast two transformation-...  \n",
       "7     We present a computer-aided design flow for ...  \n",
       "8     A novel way of picturing the processing of q...  \n",
       "9     Despite their claimed biological plausibilit...  \n",
       "10    In this paper, we describe a new, systematic...  \n",
       "11    In this paper we show how to compute the $\\L...  \n",
       "12    In this paper we give a definition of \"algor...  \n",
       "13    This paper visualizes a knot reduction algor...  \n",
       "14    The rich set of interactions between individ...  \n",
       "15    In this contribution we go through the devel...  \n",
       "16    A new expression as a certain asymptotic lim...  \n",
       "17    Product probability property, known in the l...  \n",
       "18    Statistical modeling of experimental physica...  \n",
       "19    We investigate the use of a Genetic Algorith...  \n",
       "20    A new incremental algorithm for data compres...  \n",
       "21    Hourglass is the name given here to a formal...  \n",
       "22    We present a new version of TaylUR, a Fortra...  \n",
       "23    This paper discusses the benefits of describ...  \n",
       "24    In the first section of this paper we prove ...  \n",
       "25    We propose an extrapolation technique that a...  \n",
       "26    We study universal compression of sequences ...  \n",
       "27    We measured the correlation of the times bet...  \n",
       "28    For the first time we apply the methodologie...  \n",
       "29    Based on overall experimental observations, ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = {\n",
    "    \"size\": 30,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"abstract_vector\": {\n",
    "                \"vector\": search_vector,\n",
    "                \"k\": 30\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "res = aos_client.search(index=\"metadata_arxiv\", body=query, stored_fields=[\"title\", \"categories\", \"abstract\"])\n",
    "print(f\"Got {res['hits']['total']['value']} Hits:\")\n",
    "query_result = []\n",
    "\n",
    "for hit in res['hits']['hits']:\n",
    "    row = [hit['_id'], hit['_score'], hit['fields']['title'][0], hit['fields']['categories'][0],  hit['fields']['abstract'][0]]\n",
    "    query_result.append(row)\n",
    "\n",
    "query_result_df = pd.DataFrame(data=query_result, columns=[\"_id\", \"_score\", \"title\", \"categories\", \"abstract\"])\n",
    "display(query_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf86c25-bad0-44ad-89dc-a1ed3ccad3a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# 7. LLM Summarize and pull out key information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d64df7-1c35-44ba-9394-98524378fcff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Select desired LLM from deployed endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9df44f8-27b6-42a0-b0b5-7c7ad66a3f28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available SageMaker Endpoints:\n",
      "1. meta-textgeneration-llama-2-13b-2024-01-15-04-27-30-881\n",
      "2. huggingface-pytorch-tgi-inference-2024-01-15-03-52-46-512\n",
      "3. hf-llm-mistral-7b-2024-01-12-22-18-38-063\n",
      "4. opensearch-gen-ai-llm-falcon-7b-bf16-acf36e80\n",
      "5. opensearch-gen-ai-embedding-gpt-j-6b-acf36e80\n",
      "6. RagEnginesSageMakerModelMultiAB24AEndpoint6DA7D681-7QzzdmVCz76E\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the number for the LLM model endpoint:  3\n",
      "Select the number for the Embedding model endpoint:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected LLM Endpoint: hf-llm-mistral-7b-2024-01-12-22-18-38-063\n",
      "Selected Embedding Endpoint: opensearch-gen-ai-embedding-gpt-j-6b-acf36e80\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import NoCredentialsError, ClientError\n",
    "\n",
    "def list_sagemaker_endpoints():\n",
    "    try:\n",
    "        # Create a SageMaker client\n",
    "        sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "        # List SageMaker endpoints\n",
    "        response = sagemaker_client.list_endpoints(\n",
    "            SortBy='CreationTime',\n",
    "            SortOrder='Descending'\n",
    "        )\n",
    "\n",
    "        return [endpoint['EndpointName'] for endpoint in response.get('Endpoints', [])]\n",
    "\n",
    "    except NoCredentialsError:\n",
    "        print(\"No AWS credentials found. Please configure your AWS credentials.\")\n",
    "        return []\n",
    "    except ClientError as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return []\n",
    "\n",
    "def select_endpoints(all_endpoints):\n",
    "    print(\"Available SageMaker Endpoints:\")\n",
    "    for i, endpoint in enumerate(all_endpoints, 1):\n",
    "        print(f\"{i}. {endpoint}\")\n",
    "\n",
    "    llm_index = int(input(\"Select the number for the LLM model endpoint: \")) - 1\n",
    "    embedding_index = int(input(\"Select the number for the Embedding model endpoint: \")) - 1\n",
    "\n",
    "    return all_endpoints[llm_index], all_endpoints[embedding_index]\n",
    "\n",
    "# List all available endpoints\n",
    "all_endpoints = list_sagemaker_endpoints()\n",
    "\n",
    "# Let the user select the LLM and Embedding endpoints\n",
    "if all_endpoints:\n",
    "    llm_endpoint_name, embedding_endpoint_name = select_endpoints(all_endpoints)\n",
    "    print(f\"Selected LLM Endpoint: {llm_endpoint_name}\")\n",
    "    print(f\"Selected Embedding Endpoint: {embedding_endpoint_name}\")\n",
    "else:\n",
    "    print(\"No endpoints available to select.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b9385bcb-83b6-451c-8177-20c69a14707a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for Article 1:\n",
      "generated_text:\n",
      ":\n",
      "  - Advances in semiconductor technology are contributing to the increasing\n",
      "complexity in the design of embedded systems.\n",
      "  - Architectures with novel techniques such as evolvable nature and\n",
      "autonomous behavior have engrossed lot of attention.\n",
      "  - This paper demonstrates conceptually evolvable embedded systems can be\n",
      "characterized basing on acausal nature.\n",
      "  - It is noted that in acausal systems, future input needs to be known, here we\n",
      "make a mechanism such that the system predicts the future inputs and exhibits\n",
      "pseudo acausal nature \n",
      "\n",
      "\n",
      "Response for Article 2:\n",
      "generated_text:\n",
      ":\n",
      "  * In this paper I describe a specialized algorithm for anisotropic diffusion\n",
      "determined by a field of transition rates.\n",
      "  * The algorithm can be used to describe some interesting forms of diffusion\n",
      "that occur in the study of proton motion in a network of hydrogen bonds.\n",
      "  * The algorithm produces data that require a nonstandard method of spectral\n",
      "analysis which is also developed here.\n",
      "  * Finally, I apply the algorithm to a simple specific example.\n",
      "Please provide a summary of the text:\n",
      "  In this paper I describe a specialized algorithm for anisotropic \n",
      "\n",
      "\n",
      "Response for Article 3:\n",
      "generated_text:\n",
      ":\n",
      "  - The on-line Viterbi algorithm for decoding hidden Markov models (HMMs) in\n",
      "much smaller than linear space.\n",
      "  - Our analysis on two-state HMMs suggests that the expected maximum memory\n",
      "used to decode sequence of length $n$ with $m$-state HMM can be as low as\n",
      "$\\Theta(m\\log n)$, without a significant slow-down compared to the classical\n",
      "Viterbi algorithm.\n",
      "  - Classical Viterbi algorithm requires $O(mn)$ space, which is impractical for\n",
      "analysis of long DNA sequences \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Create a SageMaker runtime client\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# Assuming 'llm_endpoint_name' contains the name of your endpoint\n",
    "# llm_endpoint_name is defined when endpoints are queried\n",
    "\n",
    "# Now let's generate new queries for each of the top 3 articles\n",
    "for index, row in query_result_df.iterrows():\n",
    "    # Break the loop after processing 3 rows\n",
    "    if index >= 3:\n",
    "        break\n",
    "\n",
    "    question = 'Please provide executive bullet points of the previous text'\n",
    "    # question = 'Please provide one sentence answers for who, what, when, where, and why of the previous text?'\n",
    "    doc = row['abstract']  # Assuming the 'abstract' field contains the text of the article\n",
    "    prompt = f\"\"\"Answer based on context:\\n\\n{doc}\\n\\n{question}\"\"\"\n",
    "    \n",
    "    # default payload\n",
    "    # payload = {\n",
    "    # \"inputs\": prompt,\n",
    "    # \"parameters\": {\n",
    "    #     \"max_new_tokens\": 1024,\n",
    "    #     \"top_k\":50,\n",
    "    #     \"top_p\":0.95,\n",
    "    #     \"do_sample\": True,\n",
    "    #     \"stop\": ['A:']\n",
    "    # }\n",
    "    # }\n",
    "    \n",
    "    # Prepare the payload for the language model\n",
    "    payload = json.dumps({\n",
    "        \"inputs\": prompt,\n",
    "        \"parameters\": {\n",
    "            \"max_new_tokens\": 128, \n",
    "            \"do_sample\": True, \n",
    "            \"temperature\": 0.2\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Make the prediction request\n",
    "    response = sagemaker_runtime.invoke_endpoint(\n",
    "        EndpointName=llm_endpoint_name,\n",
    "        ContentType='application/json',\n",
    "        Body=payload\n",
    "    )\n",
    "            \n",
    "    # Decode the response\n",
    "    response_body = json.loads(response['Body'].read().decode())\n",
    "\n",
    "    # Iterate through the response and print each item\n",
    "    print(f\"Response for Article {index + 1}:\")\n",
    "    for item in response_body:\n",
    "        for key, value in item.items():\n",
    "            # Print the key\n",
    "            print(f\"{key}:\")\n",
    "\n",
    "            # Clean up the value by removing redundant new lines and spaces\n",
    "            cleaned_value = re.sub(r'\\n\\s*\\n', '\\n', value.strip())\n",
    "\n",
    "            # Print the cleaned value\n",
    "            print(cleaned_value, \"\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a134ae94-7362-4d87-a3cb-9a9861b7b1a5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Bonus Bedrock"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528c314-0c49-4bcb-9b09-7c9e9ea89813",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Bedrock list all available models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cf56f0-a054-4af1-b77d-b87d04023363",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!aws bedrock list-foundation-models --query \"modelSummaries[*].modelId\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b068f4cd-fe48-42b6-b591-27d744fff716",
   "metadata": {},
   "source": [
    "## Bedrock AI21 J2 Ultra v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672dd6d9-0b9c-4b3d-be9f-45dad4d9507f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sample Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "388c3674-3a99-4ce7-be1b-1a42e5cd95b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "session = boto3.Session(\n",
    "    profile_name=os.environ.get(\"BWB_PROFILE_NAME\")\n",
    ") #sets the profile name to use for AWS credentials\n",
    "\n",
    "bedrock = session.client(\n",
    "    service_name='bedrock-runtime', #creates a Bedrock client\n",
    "    region_name=os.environ.get(\"BWB_REGION_NAME\"),\n",
    "    endpoint_url=os.environ.get(\"BWB_ENDPOINT_URL\")\n",
    ") \n",
    "\n",
    "bedrock_model_id = \"ai21.j2-ultra-v1\" #set the foundation model\n",
    "\n",
    "prompt = \"What is the largest city in New Hampshire?\" #the prompt to send to the model\n",
    "\n",
    "body = json.dumps({\n",
    "    \"prompt\": prompt, #AI21\n",
    "    \"maxTokens\": 1024, \n",
    "    \"temperature\": 0, \n",
    "    \"topP\": 0.5, \n",
    "    \"stopSequences\": [], \n",
    "    \"countPenalty\": {\"scale\": 0 }, \n",
    "    \"presencePenalty\": {\"scale\": 0 }, \n",
    "    \"frequencyPenalty\": {\"scale\": 0 }\n",
    "}) #build the request payload\n",
    "\n",
    "\n",
    "response = bedrock.invoke_model(body=body, modelId=bedrock_model_id, accept='application/json', contentType='application/json') #send the payload to Bedrock\n",
    "\n",
    "response_body = json.loads(response.get('body').read()) # read the response\n",
    "\n",
    "response_text = response_body.get(\"completions\")[0].get(\"data\").get(\"text\") #extract the text from the JSON response\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda48ccb-444d-48d8-9dff-f901b39595da",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process articles with AI21 J2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d25bd2ea-0cec-4b67-ad2b-a2b2372dad92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response for Article 1:\n",
      "\n",
      "Advances in semiconductor technology are contributing to the increasing complexity in the design of embedded systems. Architectures with novel techniques such as evolvable nature and autonomous behavior have engrossed a lot of attention. This paper demonstrates conceptually evolvable embedded systems can be characterized based on acausal nature. It is noted that in acausal systems, future input needs to be known, here we make a mechanism such that the system predicts the future inputs and exhibits pseudo acausal nature. An embedded system that uses theoretical framework of acausality is proposed. Our method aims at a novel architecture that features the hardware evolability and autonomous behavior alongside pseudo acausality. Various aspects of this architecture are discussed in detail along with the limitations.\n",
      "\n",
      "* Advances in semiconductor technology are contributing to the increasing complexity in the design of embedded systems.\n",
      "* Architectures with novel techniques such as evolvable nature and autonomous behavior have engrossed a lot of attention.\n",
      "* This paper demonstrates conceptually evolvable embedded systems can be characterized based on acausal nature.\n",
      "* It is noted that in acausal systems, future input needs to be known.\n",
      "* This paper proposes a mechanism where the system predicts the future inputs and exhibits pseudo acausal nature.\n",
      "* An embedded system that uses theoretical framework of acausality is proposed.\n",
      "* Our method aims at a novel architecture that features the hardware evolability and autonomous behavior alongside pseudo acausality.\n",
      "* Various aspects of this architecture are discussed in detail along with the limitations.\n",
      "\n",
      "Response for Article 2:\n",
      "\n",
      "In this paper, I describe a specialized algorithm for anisotropic diffusion determined by a field of transition rates. The algorithm can be used to model some interesting forms of diffusion that occur in the study of proton motion in a network of hydrogen bonds. The algorithm produces data that require a new method of spectral analysis, which is also developed here. Finally, I apply the algorithm to a simple specific example.\n",
      "\n",
      "Response for Article 3:\n",
      "\n",
      "In this paper, we introduce an on-line Viterbi algorithm for decoding hidden Markov models (HMMs) in much smaller than linear space. Our analysis suggests that the expected maximum memory used to decode a sequence of length $n$ with $m$-state HMM can be as low as $\\Theta(m\\log n)$, without a significant slow-down compared to the classical Viterbi algorithm. The classical Viterbi algorithm requires $O(mn)$ space, which is impractical for analysis of long DNA sequences (such as complete human genome chromosomes) and for continuous data streams. We also experimentally demonstrate the performance of the on-line Viterbi algorithm on a simple HMM for gene finding on both simulated and real DNA sequences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# Create a session with AWS using the provided profile and region details\n",
    "session = boto3.Session(\n",
    "    profile_name=os.environ.get(\"BWB_PROFILE_NAME\")\n",
    ")\n",
    "\n",
    "# Create a Bedrock runtime client\n",
    "bedrock = session.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name=os.environ.get(\"BWB_REGION_NAME\"),\n",
    "    endpoint_url=os.environ.get(\"BWB_ENDPOINT_URL\")\n",
    ")\n",
    "\n",
    "# Set the foundation model\n",
    "bedrock_model_id = \"ai21.j2-ultra-v1\"\n",
    "\n",
    "# Process each of the top 3 articles\n",
    "\n",
    "for index, row in query_result_df.iterrows():\n",
    "    # Break the loop after processing 3 rows\n",
    "    if index >= 3:\n",
    "        break\n",
    "        \n",
    "    question = 'Please provide executive bullet points of the previous text'\n",
    "    # question = 'Please provide one sentence answers for who, what, when, where, and why of the previous text?'\n",
    "    doc = row['abstract']  # Assuming the 'abstract' field contains the text of the article\n",
    "    prompt = f\"\"\"Answer based on context:\\n\\n{doc}\\n\\n{question}\"\"\"\n",
    "    \n",
    "    # Prepare the payload for the Bedrock model\n",
    "    body = json.dumps({\n",
    "        \"prompt\": prompt,\n",
    "        \"maxTokens\": 1024,\n",
    "        \"temperature\": 0.2,\n",
    "        \"topP\": 0.5,\n",
    "        \"stopSequences\": [],\n",
    "        \"countPenalty\": {\"scale\": 0},\n",
    "        \"presencePenalty\": {\"scale\": 0},\n",
    "        \"frequencyPenalty\": {\"scale\": 0}\n",
    "    })\n",
    "\n",
    "    # Make the prediction request\n",
    "    response = bedrock.invoke_model(\n",
    "        body=body,\n",
    "        modelId=bedrock_model_id,\n",
    "        accept='application/json',\n",
    "        contentType='application/json'\n",
    "    )\n",
    "\n",
    "    # Decode the response and print it\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    response_text = response_body.get(\"completions\")[0].get(\"data\").get(\"text\")\n",
    "    print(f\"Response for Article {index + 1}:\\n{response_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d71a86-128e-447e-8db4-10e78055237a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Cleanup Resources (Don't waste money if you don't have to)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73a06fb-ca67-4229-b45f-e702af77f71e",
   "metadata": {},
   "source": [
    "## Cleanup SageMaker Inference Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17e770c1-c3e7-4267-8733-1344233ce4c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active Endpoints:\n",
      "1. huggingface-pytorch-tgi-inference-2024-01-15-03-52-46-512\n",
      "2. huggingface-pytorch-tgi-inference-2024-01-15-01-25-42-790\n",
      "3. huggingface-pytorch-tgi-inference-2024-01-15-01-15-53-997\n",
      "4. huggingface-pytorch-tgi-inference-2024-01-15-00-32-07-025\n",
      "5. hf-llm-mistral-7b-2024-01-12-22-18-38-063\n",
      "6. opensearch-gen-ai-llm-falcon-7b-bf16-acf36e80\n",
      "7. opensearch-gen-ai-embedding-gpt-j-6b-acf36e80\n",
      "8. RagEnginesSageMakerModelMultiAB24AEndpoint6DA7D681-7QzzdmVCz76E\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the endpoint numbers to delete (comma-separated):  3,4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted endpoint: huggingface-pytorch-tgi-inference-2024-01-15-01-15-53-997\n",
      "Deleted endpoint: huggingface-pytorch-tgi-inference-2024-01-15-00-32-07-025\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "def list_endpoints(sagemaker_client):\n",
    "    # List all active endpoints\n",
    "    response = sagemaker_client.list_endpoints(SortBy='CreationTime', SortOrder='Descending')\n",
    "    endpoints = response['Endpoints']\n",
    "    while 'NextToken' in response:\n",
    "        response = sagemaker_client.list_endpoints(NextToken=response['NextToken'], SortBy='CreationTime', SortOrder='Descending')\n",
    "        endpoints.extend(response['Endpoints'])\n",
    "    return endpoints\n",
    "\n",
    "def delete_selected_endpoints(sagemaker_client, selected_endpoint_names):\n",
    "    for endpoint_name in selected_endpoint_names:\n",
    "        sagemaker_client.delete_endpoint(EndpointName=endpoint_name)\n",
    "        print(f\"Deleted endpoint: {endpoint_name}\")\n",
    "\n",
    "def main():\n",
    "    sagemaker_client = boto3.client('sagemaker')\n",
    "    endpoints = list_endpoints(sagemaker_client)\n",
    "\n",
    "    # Print endpoint names\n",
    "    print(\"Active Endpoints:\")\n",
    "    for i, endpoint in enumerate(endpoints):\n",
    "        print(f\"{i+1}. {endpoint['EndpointName']}\")\n",
    "\n",
    "    # User input to select endpoints\n",
    "    selected_indices = input(\"Enter the endpoint numbers to delete (comma-separated): \")\n",
    "    selected_indices = [int(x.strip()) for x in selected_indices.split(',')]\n",
    "\n",
    "    # Get endpoint names based on indices\n",
    "    selected_endpoint_names = [endpoints[i-1]['EndpointName'] for i in selected_indices]\n",
    "\n",
    "    # Delete selected endpoints\n",
    "    delete_selected_endpoints(sagemaker_client, selected_endpoint_names)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cb3904-015f-4b69-b3f4-45102ec513d1",
   "metadata": {},
   "source": [
    "## Cleanup OpenSearch Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129024a8-6ccc-4acc-8081-9f932e80e30b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "def list_domains(opensearch_client):\n",
    "    response = opensearch_client.list_domain_names()\n",
    "    return [domain['DomainName'] for domain in response['DomainNames']]\n",
    "\n",
    "def delete_domain(opensearch_client, domain_name):\n",
    "    opensearch_client.delete_domain(DomainName=domain_name)\n",
    "    print(f\"Deleted domain: {domain_name}\")\n",
    "\n",
    "def main():\n",
    "    opensearch_client = boto3.client('opensearch')\n",
    "\n",
    "    # List and select domain\n",
    "    domains = list_domains(opensearch_client)\n",
    "    print(\"Available Domains:\")\n",
    "    for i, domain in enumerate(domains):\n",
    "        print(f\"{i+1}. {domain}\")\n",
    "\n",
    "    selected_domain_indices = input(\"Enter the domain numbers to delete (comma-separated): \")\n",
    "    selected_domain_indices = [int(x.strip()) for x in selected_domain_indices.split(',')]\n",
    "\n",
    "    # Delete selected domains\n",
    "    for index in selected_domain_indices:\n",
    "        delete_domain(opensearch_client, domains[index-1])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45e0f8-cdbf-43d9-9c5a-4ca828da8b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
